{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7723308",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-26T13:50:24.935412Z",
     "iopub.status.busy": "2021-08-26T13:50:24.934846Z",
     "iopub.status.idle": "2021-08-26T13:50:25.996574Z",
     "shell.execute_reply": "2021-08-26T13:50:25.997037Z",
     "shell.execute_reply.started": "2021-08-26T12:43:01.072990Z"
    },
    "papermill": {
     "duration": 1.082137,
     "end_time": "2021-08-26T13:50:25.997299",
     "exception": false,
     "start_time": "2021-08-26T13:50:24.915162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/30-days-of-ml/sample_submission.csv\n",
      "/kaggle/input/30-days-of-ml/train.csv\n",
      "/kaggle/input/30-days-of-ml/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,auc,classification_report,confusion_matrix,mean_squared_error, precision_score, recall_score,roc_curve\n",
    "\n",
    "import time\n",
    "from numpy import absolute\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ffcca",
   "metadata": {
    "papermill": {
     "duration": 0.004746,
     "end_time": "2021-08-26T13:50:26.007711",
     "exception": false,
     "start_time": "2021-08-26T13:50:26.002965",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb57f18b",
   "metadata": {
    "papermill": {
     "duration": 0.00464,
     "end_time": "2021-08-26T13:50:26.017174",
     "exception": false,
     "start_time": "2021-08-26T13:50:26.012534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGboost + GridSeachCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7278313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T13:50:26.043228Z",
     "iopub.status.busy": "2021-08-26T13:50:26.042559Z",
     "iopub.status.idle": "2021-08-26T13:53:55.324846Z",
     "shell.execute_reply": "2021-08-26T13:53:55.324368Z",
     "shell.execute_reply.started": "2021-08-26T12:43:01.089618Z"
    },
    "papermill": {
     "duration": 209.302962,
     "end_time": "2021-08-26T13:53:55.324991",
     "exception": false,
     "start_time": "2021-08-26T13:50:26.022029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 1 to 499999\n",
      "Data columns (total 25 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat0    300000 non-null  object \n",
      " 1   cat1    300000 non-null  object \n",
      " 2   cat2    300000 non-null  object \n",
      " 3   cat3    300000 non-null  object \n",
      " 4   cat4    300000 non-null  object \n",
      " 5   cat5    300000 non-null  object \n",
      " 6   cat6    300000 non-null  object \n",
      " 7   cat7    300000 non-null  object \n",
      " 8   cat8    300000 non-null  object \n",
      " 9   cat9    300000 non-null  object \n",
      " 10  cont0   300000 non-null  float64\n",
      " 11  cont1   300000 non-null  float64\n",
      " 12  cont2   300000 non-null  float64\n",
      " 13  cont3   300000 non-null  float64\n",
      " 14  cont4   300000 non-null  float64\n",
      " 15  cont5   300000 non-null  float64\n",
      " 16  cont6   300000 non-null  float64\n",
      " 17  cont7   300000 non-null  float64\n",
      " 18  cont8   300000 non-null  float64\n",
      " 19  cont9   300000 non-null  float64\n",
      " 20  cont10  300000 non-null  float64\n",
      " 21  cont11  300000 non-null  float64\n",
      " 22  cont12  300000 non-null  float64\n",
      " 23  cont13  300000 non-null  float64\n",
      " 24  target  300000 non-null  float64\n",
      "dtypes: float64(15), object(10)\n",
      "memory usage: 59.5+ MB\n",
      "X_train_full shape:  (240000, 24)\n",
      "X_valid_full shape:  (60000, 24)\n",
      "y_train shape:  (240000,)\n",
      "y_valid shape:  (60000,)\n",
      "Categorical columns:  ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\n",
      "numerical columns:  ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\n",
      "X_test shape:  (200000, 24)\n",
      "Training time =  0:02:59\n",
      "0.7234812995706992\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=11, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=30000, n_jobs=2, num_parallel_tree=1,\n",
      "             objective='reg:linear', random_state=42, reg_alpha=0, reg_lambda=1,\n",
      "             scale_pos_weight=1, silent=True, subsample=0.8,\n",
      "             tree_method='gpu_hist', validate_parameters=1, verbosity=0)\n",
      "{'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 30000, 'objective': 'reg:linear', 'random_state': 42, 'silent': True, 'subsample': 0.8, 'tree_method': 'gpu_hist', 'verbosity': 0}\n",
      "-0.7214344995615624\n"
     ]
    }
   ],
   "source": [
    "# Load and review train data\n",
    "train_data = pd.read_csv(\"/kaggle/input/30-days-of-ml/train.csv\", low_memory=False, index_col='id')\n",
    "test_data = pd.read_csv(\"/kaggle/input/30-days-of-ml/test.csv\", low_memory=False, index_col='id')\n",
    "#submission_example = pd.read_csv(\"/kaggle/input/30-days-of-ml/sample_submission.csv\", low_memory=False)\n",
    "\n",
    "train_data.info()\n",
    "\n",
    "object_cols=train_data.columns[1:10]\n",
    "object_nunique = list(map(lambda col: train_data[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "#sorted(d.items(), key=lambda x: x[1])\n",
    "\n",
    "# Separate target from predictors\n",
    "y = train_data.target\n",
    "X = train_data.drop(['target'], axis=1) # Remove target and Id\n",
    "\n",
    "#cols_with_missing = [col for col in X_train.columns\n",
    "                     #if X_train[col].isnull().any()]\n",
    "\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, \n",
    "                                                                test_size=0.2,random_state=0)\n",
    "\n",
    "print(\"X_train_full shape: \",X_train_full.shape)\n",
    "print(\"X_valid_full shape: \",X_valid_full.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"y_valid shape: \",y_valid.shape)\n",
    "\n",
    "\n",
    "# Separate categorical and numerical columns (all categorical)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 20 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "print(\"Categorical columns: \", categorical_cols)\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']] \n",
    "print(\"numerical columns: \",numerical_cols)\n",
    "\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "\n",
    "#Save all the columns to use for training\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = test_data[my_cols].copy()\n",
    "\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_valid_transformed  = preprocessor.transform(X_valid)\n",
    "X_test_transformed  = preprocessor.transform(X_test)\n",
    "#print(X_train_transformed)\n",
    "#print(X_valid_transformed)\n",
    "\n",
    "# Define the model \n",
    "xgb_model = XGBRegressor()\n",
    "#xgb_model.get_params()\n",
    "\n",
    "xgb_params = {'objective': ['reg:linear'],\n",
    "              'n_estimators': [30000],\n",
    "              'learning_rate': [0.01],\n",
    "              'subsample': [0.8],\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              #'reg_lambda': [68.1],\n",
    "              #'reg_alpha': [15.7],\n",
    "              'random_state': [42],\n",
    "              'tree_method': ['gpu_hist'],\n",
    "              'verbosity': [0],\n",
    "              'silent': [True]\n",
    "              }\n",
    "gs = GridSearchCV(xgb_model,\n",
    "                  cv=10,\n",
    "                  scoring='neg_root_mean_squared_error',\n",
    "                  verbose=0,\n",
    "                  param_grid=xgb_params)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gs.fit(X_train_transformed, y_train, \n",
    "       early_stopping_rounds=5, \n",
    "       eval_set=[(X_valid_transformed, y_valid)],\n",
    "       verbose=False)\n",
    "\n",
    "stop = time.time()\n",
    "print(\"Training time = \", timedelta(seconds=int(stop-start)))\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds_valid = gs.best_estimator_.predict(X_valid_transformed)\n",
    "mse_score=mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "print(mse_score)\n",
    "\n",
    "# Use the model to generate predictions\n",
    "predictions = gs.best_estimator_.predict(X_test_transformed)\n",
    "print(gs.best_estimator_)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'target': predictions})\n",
    "output.to_csv('xgboost_gs_tuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6153f",
   "metadata": {
    "papermill": {
     "duration": 0.006195,
     "end_time": "2021-08-26T13:53:55.338060",
     "exception": false,
     "start_time": "2021-08-26T13:53:55.331865",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a96a7",
   "metadata": {
    "papermill": {
     "duration": 0.006139,
     "end_time": "2021-08-26T13:53:55.350777",
     "exception": false,
     "start_time": "2021-08-26T13:53:55.344638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ed7de7",
   "metadata": {
    "papermill": {
     "duration": 0.006206,
     "end_time": "2021-08-26T13:53:55.363390",
     "exception": false,
     "start_time": "2021-08-26T13:53:55.357184",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 218.704671,
   "end_time": "2021-08-26T13:53:56.923218",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-26T13:50:18.218547",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
